{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_tensorboard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/samsam915/CEP-Resources/blob/master/mnist_tensorboard.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vfRzp6SkRY5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "cellView": "both",
        "outputId": "f3e0f429-3527-4800-ccb5-02ead1507c66"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os \n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "#导入数据\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "DIR_log = 'mnist/'\n",
        "niter = 500\n",
        "interval = 100\n",
        "\n",
        "if not os.path.exists(DIR_log):\n",
        "    os.mkdir(DIR_log)\n",
        "    \n",
        "#初始化权重\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial,name='weight')\n",
        "\n",
        "#初始化偏差\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial,name='bias')\n",
        "\n",
        "#卷积层\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "#池化层\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "#定义卷积和池化层\n",
        "def conv_pool(x_image,in_shape,out_shape):\n",
        "            \n",
        "    W_conv = weight_variable([5,5,in_shape,out_shape])     \n",
        "    b_conv = bias_variable([out_shape])\n",
        "    h_conv = tf.nn.relu(conv2d(x_image, W_conv) + b_conv) \n",
        "    h_pool = max_pool_2x2(h_conv)                          \n",
        "    \n",
        "    conv_feature_shape = h_conv.get_shape()[1]\n",
        "    pool_feature_shape = h_pool.get_shape()[1]\n",
        "    \n",
        "    #可视化特征图\n",
        "    tf.summary.image('feature_conv', tf.reshape(tf.reduce_mean(h_conv,axis=3),(-1,conv_feature_shape,conv_feature_shape,1)), 3)\n",
        "    tf.summary.image('feature_pool', tf.reshape(tf.reduce_mean(h_pool,axis=3),(-1,pool_feature_shape,pool_feature_shape,1)), 3)\n",
        "    \n",
        "    #数据分布图\n",
        "    tf.summary.histogram('W_con',W_conv)\n",
        "    tf.summary.histogram('b_con',b_conv)\n",
        "    \n",
        "    return h_pool\n",
        "\n",
        "#生成全景图像文件。\n",
        "#tensorboard可以从全景图中按序裁剪出每一幅手写体图像，在页面上独立渲染。\n",
        "def create_sprite_image(images):\n",
        "    if isinstance(images, list):\n",
        "        images = np.array(images)\n",
        "    img_h = images.shape[1]\n",
        "    img_w = images.shape[2]\n",
        "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "    \n",
        "    \n",
        "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
        "    \n",
        "    for i in range(n_plots):\n",
        "        for j in range(n_plots):\n",
        "            this_filter = i * n_plots + j\n",
        "            if this_filter < images.shape[0]:\n",
        "                this_img = images[this_filter]\n",
        "                spriteimage[i * img_h:(i + 1) * img_h,\n",
        "                  j * img_w:(j + 1) * img_w] = this_img\n",
        "    \n",
        "    return spriteimage\n",
        "\n",
        "def vector_to_matrix_mnist(mnist_digits):\n",
        "    return np.reshape(mnist_digits,(-1,28,28))\n",
        "\n",
        "def invert_grayscale(mnist_digits):\n",
        "    return 1-mnist_digits\n",
        "\n",
        "def save_sprite():\n",
        "    to_visualise = (mnist.test.images[:10000])\n",
        "    to_visualise = vector_to_matrix_mnist(to_visualise)\n",
        "    to_visualise = invert_grayscale(to_visualise)\n",
        "    sprite_image = create_sprite_image(to_visualise)\n",
        "    plt.imsave(os.path.join(DIR_log,'mnist_10k_sprite.png'),sprite_image,cmap='gray')\n",
        "    \n",
        "class Mnist(object):\n",
        "    def __init__(self):\n",
        "        #定义一个会话\n",
        "        self.sess = tf.Session()\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "        \n",
        "        #载入图片    \n",
        "        self.embedding_var = tf.Variable(tf.stack(mnist.test.images[:10000]),trainable=False,name='embedding')\n",
        "        \n",
        "    def mnist_network(self):\n",
        "        with tf.name_scope('a_intput'):\n",
        "            #模型输入\n",
        "            self.xs = tf.placeholder(tf.float32, [None, 784],name='x')     \n",
        "            self.ys = tf.placeholder(tf.float32, [None, 10],name='y') \n",
        "            #[n_samples,28*28]的一维向量转为[n_samples,28,28,1]的图像\n",
        "            x_image = tf.reshape(self.xs, [-1, 28, 28, 1])\n",
        "            tf.summary.image('_input', x_image, 3)\n",
        "    \n",
        "        with tf.name_scope('conv1'):\n",
        "            ##第一层卷积和池化\n",
        "            #输入尺寸[n_samples,28,28,1]\n",
        "            #输出尺寸[n_samples,14,14,32]\n",
        "            h_pool1 = conv_pool(x_image,1,32)\n",
        "        \n",
        "        \n",
        "        with tf.name_scope('conv2'):\n",
        "            ##第二层卷积层和池化层\n",
        "            #输入尺寸[n_samples,14,14,32]\n",
        "            #输出尺寸[n_samples,7,7,64]\n",
        "            h_pool2 = conv_pool(h_pool1,32,64)\n",
        "        \n",
        "        with tf.name_scope('fc1'):\n",
        "            #转换为[n_samples,7*7*64]的一维向量\n",
        "            h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])  \n",
        "            \n",
        "            #全连接层fc1\n",
        "            W_fc1 = weight_variable([7*7*64, 1024])\n",
        "            b_fc1 = bias_variable([1024])\n",
        "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "            \n",
        "            #数据分布图\n",
        "            tf.summary.histogram('W_fc1', W_fc1)\n",
        "            tf.summary.histogram('b_fc1', b_fc1)\n",
        "            \n",
        "            #dropout\n",
        "            self.keep_prob = tf.placeholder(tf.float32)\n",
        "            h_fc1_drop = tf.nn.dropout(h_fc1, self.keep_prob)\n",
        "        \n",
        "        with tf.name_scope('fc2'):\n",
        "            #计算概率输出\n",
        "            W_fc2 = weight_variable([1024, 10])\n",
        "            b_fc2 = bias_variable([10])\n",
        "            pred = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
        "            \n",
        "            #数据分布图\n",
        "            tf.summary.histogram('W_fc1', W_fc2)\n",
        "            tf.summary.histogram('b_fc1', b_fc2)\n",
        "            \n",
        "        with tf.name_scope('loss'):\n",
        "            #交叉熵损失\n",
        "            cross_entropy = tf.reduce_mean(-tf.reduce_sum(self.ys * tf.log(pred),reduction_indices=[1]))    \n",
        "            #添加获取交叉熵的汇总操作\n",
        "            tf.summary.scalar('loss',cross_entropy)  \n",
        "        with tf.name_scope('train'):\n",
        "            #优化器\n",
        "            train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy,global_step=self.global_step)\n",
        "            \n",
        "        with tf.name_scope('accuracy'):\n",
        "            #精确度\n",
        "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(self.ys, 1))\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "            #添加获取准确率的汇总操作\n",
        "            tf.summary.scalar('accuracy',accuracy)\n",
        "            \n",
        "        #合并所有的summary\n",
        "        merged = tf.summary.merge_all()\n",
        "        \n",
        "        return train_step, accuracy, merged \n",
        "\n",
        "    #可视化\n",
        "    def vis(self):\n",
        "        #创建元数据文件，将嵌入变量保存到checkpoint文件中\n",
        "        metadata_file = os.path.join(DIR_log,'metadata.tsv')\n",
        "    \n",
        "        with open(metadata_file,'w') as f:\n",
        "            for i in  range(10000):\n",
        "                c = np.nonzero(mnist.test.labels[::1])[1:][0][i]\n",
        "                f.write('{}\\n'.format(c))\n",
        "    \n",
        "        #创建投影配置参数\n",
        "        projector_writer = tf.summary.FileWriter(DIR_log,tf.get_default_graph())\n",
        "        config = projector.ProjectorConfig()\n",
        "        embeddings = config.embeddings.add()\n",
        "        embeddings.tensor_name = self.embedding_var.name\n",
        "        embeddings.metadata_path = 'metadata.tsv'\n",
        "    \n",
        "        #设置全景图文件路径和手写体数字图像的尺寸\n",
        "        embeddings.sprite.image_path = os.path.join('mnist_10k_sprite.png')\n",
        "        embeddings.sprite.single_image_dim.extend([28,28])\n",
        "        #执行可视化方法，讲参数配置写入新传概念的投影配置文件中\n",
        "        #tensorboard启动时会自动加载该文件中的投影参数配置\n",
        "        projector.visualize_embeddings(projector_writer,config)\n",
        "        \n",
        "\n",
        "    def train(self,train_step, accuracy, merged):\n",
        "        #初始化所有变量\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "        #定义事件文件\n",
        "        self.writer_train = tf.summary.FileWriter(os.path.join(DIR_log,'train'),tf.get_default_graph())\n",
        "        # 注意此处不需要sess.graph\n",
        "        self.writer_val = tf.summary.FileWriter(os.path.join(DIR_log,'val'))\n",
        "        saver = tf.train.Saver()\n",
        "        \n",
        "        #开始训练时间\n",
        "        start_time = time.time()\n",
        "    \n",
        "        #开始训练\n",
        "        for i in range(niter):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "            _,step = self.sess.run([train_step,self.global_step], feed_dict={self.xs: batch_xs, self.ys: batch_ys, self.keep_prob: 0.5})\n",
        "    \n",
        "            if step % interval == 0:\n",
        "                #训练集精度\n",
        "                train_start_time = time.time()\n",
        "                train_accuracy_res,train_summary = self.sess.run([accuracy,merged], feed_dict={self.xs: batch_xs, self.ys: batch_ys, self.keep_prob: 1.0})\n",
        "                train_end_time = time.time()\n",
        "                self.writer_train.add_summary(train_summary,step)\n",
        "                print( \"step %d,  train accuracy %.2g   time: %.3gs\" % (step,train_accuracy_res,train_end_time-train_start_time))\n",
        "    \n",
        "                #验证集精度\n",
        "                val_start_time = time.time()\n",
        "                val_accuracy_res,val_summary = self.sess.run([accuracy,merged], feed_dict={self.xs: mnist.validation.images,self.ys: mnist.validation.labels, self.keep_prob: 1.0})\n",
        "                val_end_time = time.time()\n",
        "                self.writer_val.add_summary(val_summary,step)\n",
        "                print( \"           val   accuracy %.2g   time: %.3gs\"  % ( val_accuracy_res,val_end_time-val_start_time))\n",
        "    \n",
        "        end_time = time.time()\n",
        "        print('total time: %gs' %  (end_time-start_time))\n",
        "    \n",
        "        saver.save(self.sess, os.path.join(DIR_log,\"model.cpkt\"),global_step=self.global_step)\n",
        "\n",
        "        print (\"test accuracy %g\" % self.sess.run(accuracy, feed_dict={self.xs : mnist.test.images,self.ys: mnist.test.labels, self.keep_prob: 1.0}))\n",
        "        \n",
        "        self.sess.close()\n",
        "        print(\"DONE\")\n",
        "    \n",
        "    def retrain(self,train_step, accuracy, merged):\n",
        "        #定义事件文件\n",
        "        self.writer_train = tf.summary.FileWriter(os.path.join(DIR_log,'train'),tf.get_default_graph())\n",
        "        # 注意此处不需要sess.graph\n",
        "        self.writer_val = tf.summary.FileWriter(os.path.join(DIR_log,'val'))\n",
        "        saver = tf.train.Saver()\n",
        "        \n",
        "        ckpt = tf.train.get_checkpoint_state(DIR_log)\n",
        "        step = int(ckpt.model_checkpoint_path.split('-')[-1])\n",
        "        saver.restore(self.sess,ckpt.model_checkpoint_path)\n",
        "        \n",
        "        #开始训练时间\n",
        "        start_time = time.time()\n",
        "        \n",
        "        #开始训练\n",
        "        for i in range(step,niter):\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "            _,step = self.sess.run([train_step,self.global_step], feed_dict={self.xs: batch_xs, self.ys: batch_ys, self.keep_prob: 0.5})\n",
        "    \n",
        "            if step % interval == 0:\n",
        "                #训练集精度\n",
        "                train_start_time = time.time()\n",
        "                train_accuracy_res,train_summary = self.sess.run([accuracy,merged], feed_dict={self.xs: batch_xs, self.ys: batch_ys, self.keep_prob: 1.0})\n",
        "                train_end_time = time.time()\n",
        "                self.writer_train.add_summary(train_summary,step)\n",
        "                print( \"step %d,  train accuracy %.2g   time: %.3gs\" % (step,train_accuracy_res,train_end_time-train_start_time))\n",
        "    \n",
        "                #验证集精度\n",
        "                val_start_time = time.time()\n",
        "                val_accuracy_res,val_summary = self.sess.run([accuracy,merged], feed_dict={self.xs: mnist.validation.images,self.ys: mnist.validation.labels, self.keep_prob: 1.0})\n",
        "                val_end_time = time.time()\n",
        "                self.writer_val.add_summary(val_summary,step)\n",
        "                print( \"           val   accuracy %.2g   time: %.3gs\"  % ( val_accuracy_res,val_end_time-val_start_time))\n",
        "        saver.save(self.sess, os.path.join(DIR_log,\"model.cpkt\"),global_step=self.global_step)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print('total time: %gs' %  (end_time-start_time))\n",
        "    \n",
        "        saver.save(self.sess, os.path.join(DIR_log,\"model.cpkt\"),global_step=self.global_step)\n",
        "\n",
        "        print (\"test accuracy %g\" % self.sess.run(accuracy, feed_dict={self.xs : mnist.test.images,self.ys: mnist.test.labels, self.keep_prob: 1.0}))\n",
        "        \n",
        "        self.sess.close()\n",
        "        print(\"DONE\")\n",
        "         \n",
        "def cpu():\n",
        "    with tf.device('/cpu:0'):\n",
        "        #重置默认的图\n",
        "        #tf.reset_default_graph()\n",
        "        \n",
        "        cpu = Mnist()\n",
        "        train_step, accuracy, merged  = cpu.mnist_network()\n",
        "        cpu.vis()\n",
        "        cpu.train(train_step, accuracy, merged)\n",
        "        \n",
        "def gpu():    \n",
        "    #测试GPU\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    \n",
        "    #重置默认的图\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    gpu = Mnist()\n",
        "    train_step, accuracy, merged  = gpu.mnist_network()\n",
        "    gpu.vis()\n",
        "    \n",
        "    if not tf.train.get_checkpoint_state(DIR_log):\n",
        "        gpu.train(train_step, accuracy, merged)\n",
        "    else:\n",
        "        gpu.retrain(train_step, accuracy, merged)  \n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    #保存全景图像\n",
        "    save_sprite()\n",
        "    #重置默认的图\n",
        "    #tf.reset_default_graph()\n",
        "    #print(\"Using CPU ......\")\n",
        "    #cpu()\n",
        "    \n",
        "    print(\"#\"*50)\n",
        "    print(\"Using GPU ......\")\n",
        "    gpu()\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "##################################################\n",
            "Using GPU ......\n",
            "Found GPU at: /device:GPU:0\n",
            "step 100,  train accuracy 0.9   time: 0.221s\n",
            "           val   accuracy 0.87   time: 0.229s\n",
            "step 200,  train accuracy 0.92   time: 0.172s\n",
            "           val   accuracy 0.93   time: 0.308s\n",
            "step 300,  train accuracy 0.91   time: 0.168s\n",
            "           val   accuracy 0.94   time: 0.198s\n",
            "step 400,  train accuracy 0.91   time: 0.169s\n",
            "           val   accuracy 0.95   time: 0.235s\n",
            "step 500,  train accuracy 0.97   time: 0.164s\n",
            "           val   accuracy 0.95   time: 0.228s\n",
            "total time: 8.63001s\n",
            "test accuracy 0.9544\n",
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FT1_5ov9R0rS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xI7Kar7dymj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "01f21143-6f3a-4102-d639-507072d6ef00"
      },
      "cell_type": "code",
      "source": [
        "!cat mnist/projector_config.pbtxt"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings {\n",
            "  tensor_name: \"embedding:0\"\n",
            "  metadata_path: \"metadata.tsv\"\n",
            "  sprite {\n",
            "    image_path: \"mnist_10k_sprite.png\"\n",
            "    single_image_dim: 28\n",
            "    single_image_dim: 28\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oH5CS6esRvm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3a114fd-2caf-4457-d6cb-70a4054a58fc"
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'mnist/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir={} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://10edeb0c.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NSIhOrdLIfD-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r mnist*/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "inNABwI_BnEV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp mnist/metadata.tsv mnist/val/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xq_qhx1JxCTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "145f6adc-8750-4479-ea75-2396942eb67e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.11.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}